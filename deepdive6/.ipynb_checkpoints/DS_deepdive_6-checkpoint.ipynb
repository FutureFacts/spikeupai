{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melbourne Housing Snapshot data\n",
    "https://www.kaggle.com/datasets/dansbecker/melbourne-housing-snapshot \n",
    "\n",
    "# About Dataset\n",
    "## Context\n",
    "\n",
    "Melbourne real estate is BOOMING. Can you find the insight or predict the next big trend to become a real estate mogul… or even harder, to snap up a reasonably priced 2-bedroom unit?\n",
    "\n",
    "## Content\n",
    "\n",
    "This is a snapshot of a dataset created by Tony Pino.\n",
    "\n",
    "It was scraped from publicly available results posted every week from Domain.com.au. He cleaned it well, and now it's up to you to make data analysis magic. The dataset includes Address, Type of Real estate, Suburb, Method of Selling, Rooms, Price, Real Estate Agent, Date of Sale and distance from C.B.D.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on specific variables\n",
    "Rooms: Number of rooms\n",
    "\n",
    "Price: Price in dollars\n",
    "\n",
    "Method: S - property sold; SP - property sold prior; PI - property passed in; PN - sold prior not disclosed; SN - sold not disclosed; NB - no bid; VB - vendor bid; W - withdrawn prior to auction; SA - sold after auction; SS - sold after auction price not disclosed. N/A - price or highest bid not available.\n",
    "\n",
    "Type: br - bedroom(s); h - house,cottage,villa, semi,terrace; u - unit, duplex; t - townhouse; dev site - development site; o res - other residential.\n",
    "\n",
    "SellerG: Real Estate Agent\n",
    "\n",
    "Date: Date sold\n",
    "\n",
    "Distance: Distance from CBD\n",
    "\n",
    "Regionname: General Region (West, North West, North, North east …etc)\n",
    "\n",
    "Propertycount: Number of properties that exist in the suburb.\n",
    "\n",
    "Bedroom2 : Scraped # of Bedrooms (from different source)\n",
    "\n",
    "Bathroom: Number of Bathrooms\n",
    "\n",
    "Car: Number of carspots\n",
    "\n",
    "Landsize: Land Size\n",
    "\n",
    "BuildingArea: Building Size\n",
    "\n",
    "CouncilArea: Governing council for the area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgements\n",
    "\n",
    "This is intended as a static (unchanging) snapshot of https://www.kaggle.com/anthonypino/melbourne-housing-market. It was created in September 2017. Additionally, homes with no Price have been removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's import the necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Next, load the dataset\n",
    "df = pd.read_csv('data/melb_data.csv') # replace with your CSV's path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get a quick overview of the dataset we can use .info()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also take a look at the first few rows of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's investigate the \"Price\" column\n",
    "price = df['Price']\n",
    "\n",
    "# We can get the minimum, maximum and average price as follows\n",
    "min_price = price.min()\n",
    "max_price = price.max()\n",
    "average_price = price.mean()\n",
    "\n",
    "print(f\"Minimum Price: {min_price}\")\n",
    "print(f\"Maximum Price: {max_price}\")\n",
    "print(f\"Average Price: {average_price}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandas Describe \n",
    "The describe method in pandas is a very powerful tool for quickly summarizing data, and it can be used with both numeric and non-numeric (also known as categorical or object) data types. \n",
    "\n",
    "For the numeric columns, describe() will provide the count, mean, standard deviation, minimum, 25th percentile (Q1), median (50th percentile), 75th percentile (Q3), and maximum.\n",
    "\n",
    "For non-numeric columns, describe() will provide the count, unique (number of distinct objects in the column), top (most frequently occurring object), and freq (frequency of the most common object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe is a good method to quickly profile all numeric columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling and visualizing\n",
    "**An image says more than a 1000 words**. It is really powerfull to visualize your data during profiling. It doesn't need to be perfectly clean to do this. \n",
    "\n",
    "### Visualize the data with a histogram\n",
    "A histogram gives us a visual representation of the data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a histogram of the price\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(df['Price'], bins=50, edgecolor='black')\n",
    "plt.title('Distribution of Prices')\n",
    "plt.xlabel('Price ($)')\n",
    "plt.xticks(ticks = plt.xticks()[0], labels = [f'{int(x/1e6)}M' for x in plt.xticks()[0]]) # This line formats the x-axis\n",
    "plt.xlim(left=0)  # This line sets the left limit of the x-axis to 0\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying outliers\n",
    "Outliers can be identified using a boxplot. Points that are determined to be outliers are marked as dots while the other observations are shown as boxes (interquartile range) and whiskers (1.5*interquartile range)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a boxplot for price\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.boxplot(df['Price'], vert=False)\n",
    "plt.title('Boxplot of Prices')\n",
    "plt.xlabel('Price ($)')\n",
    "plt.xlim(left=0)  # This line sets the left limit of the x-axis to 0\n",
    "\n",
    "plt.xticks(ticks = plt.xticks()[0], labels = [f'{int(x/1e6)}M' for x in plt.xticks()[0]]) # This line formats the x-axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "**Now it is your turn!**\n",
    "\n",
    "Preferably work in groups of 4. Two people create the plots for the number of rooms and two people for the landsize (Pair programming). Help each other if you get stuck.\n",
    "\n",
    "- Rooms\n",
    "    - Histogram\n",
    "    - Boxplot\n",
    "- Landsize\n",
    "    - Histogram\n",
    "    - Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO \n",
    "# your Histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['Rooms'], bins=9, edgecolor='black')\n",
    "plt.title('Distribution of Number of Rooms')\n",
    "plt.xlabel('Number of Rooms')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Histogram of landsize\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['Landsize'], bins=50, edgecolor='black')\n",
    "plt.title('Distribution of Landsize')\n",
    "plt.xlabel('Landsize')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO \n",
    "# your Boxplot\n",
    "# Boxplot of the number of rooms\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(df['Rooms'], vert=False)\n",
    "plt.title('Boxplot of Number of Rooms')\n",
    "plt.xlabel('Number of Rooms')\n",
    "plt.show()\n",
    "\n",
    "# Boxplot of landsize\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(df['Landsize'], vert=False)\n",
    "plt.title('Boxplot of Landsize')\n",
    "plt.xlabel('Landsize')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Completeness\n",
    "Missing values in your data can sometimes cause a lot of issues. \n",
    "\n",
    "In data science, identifying missing values and checking data completeness is vital for accurate analysis, reliable results, and data integrity. Missing values can bias statistical analysis, affect predictive models, and signal data quality issues. By addressing missing values, data scientists can ensure data quality, make informed decisions about imputation or removal, and derive meaningful insights.\n",
    "\n",
    "\n",
    "\n",
    "**QUESTION** \n",
    "\n",
    "- What would you do with incomplete data? \n",
    "- Filling the missing data?\n",
    "    - What value do you choose?\n",
    "- Drop the column with the missing values?\n",
    "- Drop the rows with the missing values?\n",
    "- Leave them empty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = ['Date', 'Price', 'Rooms', 'Landsize', 'BuildingArea', 'YearBuilt']\n",
    "missing_values = df[columns_to_check].isnull().sum()\n",
    "\n",
    "print(\"Missing values:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dangers of missing values\n",
    "In dashboarding and data science, missing values can lead to problems such as biased analysis, incomplete insights, distorted visualizations, impaired predictive models, data integrity concerns, and user misinterpretation. Handling missing values properly is crucial to ensure accurate and reliable analysis, maintain data integrity, and prevent misleading or incomplete results.\n",
    "\n",
    "- Machine Learning models often can't handle missing values. Either drop them or fill them\n",
    "- Users can misinterpret your data if the missing values are not clearly communicated\n",
    "- Missing values can indicate underlying data quality issues\n",
    "\n",
    "To mitigate these issues, it is crucial to handle missing values appropriately by employing techniques such as data imputation, removal of incomplete cases, or utilizing specialized models capable of handling missing values. Proper documentation and transparency regarding the handling of missing values in the dashboard are also essential to ensure data integrity and user understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations\n",
    "**Importance of Finding Correlations in Data**\n",
    "\n",
    "Identifying correlations in data is crucial for data science. Correlations reveal relationships between variables, providing valuable insights and aiding decision-making. They help discover patterns, select meaningful features, guide data preprocessing, and inspire new hypotheses. By leveraging correlations effectively, data scientists gain a deeper understanding of the data and enhance their analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_correlate = ['Rooms', 'Price', 'Landsize']\n",
    "correlation_matrix = df[columns_to_correlate].corr()\n",
    "\n",
    "print(\"Correlation matrix:\")\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the Correlation Matrix\n",
    "\n",
    "The correlation matrix reveals the relationships between variables. In this case:\n",
    "- \"Rooms\" and \"Price\" have a moderate positive correlation (approximately 0.497). More rooms tend to be associated with higher prices. - \"Rooms\" and \"Landsize,\" as well as \"Price\" and \"Landsize,\" have very weak positive correlations (approximately 0.026 and 0.038, respectively). There is a slight tendency for larger land sizes as the number of rooms or price increases.\n",
    "\n",
    "These correlations provide insights into how the variables are related."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "Are the date (of sale) and price correlated?\n",
    "\n",
    "- Try to find if there is a correlation\n",
    "- *hint: make a plot*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2 TODO\n",
    "\n",
    "# Scatter plot of Date vs. Price\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['Date'], df['Price'], alpha=0.2)\n",
    "plt.title('Date vs. Price')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "\n",
    "# Select a subset of x-tick labels for better readability\n",
    "unique_dates = df['Date'].unique()\n",
    "x_ticks = unique_dates[::2]  # With this list slicing we only take every second element\n",
    "\n",
    "# + Rotate and allign the ticks\n",
    "# only plot a subset of the dates to increase readabality\n",
    "plt.xticks(x_ticks, rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()  # Adjust the layout to prevent overlapping\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Date and calculate the average price per date\n",
    "date_price_avg = df.groupby('Date')['Price'].mean()\n",
    "\n",
    "# Line plot of Date vs. Average Price\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(date_price_avg.index, date_price_avg.values, '-o', markersize=3)\n",
    "plt.title('Date vs. Average Price')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Average Price')\n",
    "\n",
    "# Select a subset of x-tick labels for better readability\n",
    "x_ticks = date_price_avg.index[::2]  # Modify the slicing value as per your preference\n",
    "\n",
    "plt.xticks(x_ticks, rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()  # Adjust the layout to prevent overlapping\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # is automatically installed with Pandas\n",
    "# It's also possible to add a trendline to the datapoints\n",
    "\n",
    "# Group by Date and calculate the average price per date\n",
    "date_price_avg = df.groupby('Date')['Price'].mean()\n",
    "\n",
    "# Line plot of Date vs. Average Price\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(date_price_avg.index, date_price_avg.values, '-o', markersize=3, label='Average Price')\n",
    "\n",
    "# Add trendline using linear regression\n",
    "poly_fit = pd.Series(np.polyfit(range(len(date_price_avg)), date_price_avg.values, 1))\n",
    "trendline = pd.Series(np.polyval(poly_fit, range(len(date_price_avg))))\n",
    "plt.plot(date_price_avg.index, trendline, color='red', label='Trendline')\n",
    "\n",
    "plt.title('Date vs. Average Price')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Average Price')\n",
    "plt.legend()\n",
    "\n",
    "# Select a subset of x-tick labels for better readability\n",
    "x_ticks = date_price_avg.index[::2]  # Modify the slicing value as per your preference\n",
    "\n",
    "plt.xticks(x_ticks, rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()  # Adjust the layout to prevent overlapping\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby + agg\n",
    "The groupby() function in pandas is used to group data based on one or more columns. It allows you to split the dataset into groups based on unique values in the specified column(s).\n",
    "\n",
    "The agg() function, short for \"aggregation,\" is then applied to calculate summary statistics or perform computations within each group. It enables you to apply one or more aggregation functions, such as mean(), sum(), max(), min(), or custom functions, to derive aggregated results for each group.\n",
    "\n",
    "By using groupby() in combination with agg(), you can efficiently analyze and summarize data across different categories or segments. It enables you to calculate statistics, extract key insights, and understand the relationships between variables within each group.\n",
    "\n",
    "This combination is particularly useful when you want to analyze and compare data across groups, perform calculations based on specific criteria, or generate aggregated results for further analysis or visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_price_avg = df.groupby('Regionname')['Price'].agg('mean') \n",
    "region_price_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is also possible to use a list of aggregation methods\n",
    "region_price_stats = df.groupby('Regionname')['Price'].agg(['count', 'mean', 'min', 'max'])\n",
    "region_price_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "Explore the relationship between number of rooms and price.\n",
    "\n",
    "Use:\n",
    "\n",
    "- .groupby()\n",
    "- Make a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO EXERCISE 3 \n",
    "\n",
    "# Group by the number of rooms and calculate the average price\n",
    "rooms_price_avg = df.groupby('Rooms')['Price'].mean()\n",
    "\n",
    "# Create a plot of the average price based on the number of rooms\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(rooms_price_avg.index, rooms_price_avg.values, '-o')\n",
    "plt.title('Number of Rooms vs. Average Price')\n",
    "plt.xlabel('Number of Rooms')\n",
    "plt.ylabel('Average Price')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Regionname and Rooms, and calculate the average price\n",
    "region_rooms_price_avg = df.groupby(['Regionname', 'Rooms'])['Price'].mean()\n",
    "\n",
    "# Get unique Regionname categories\n",
    "region_names = df['Regionname'].unique()\n",
    "\n",
    "# Create subplots for each Regionname category\n",
    "fig, axs = plt.subplots(len(region_names), figsize=(10, 6*len(region_names)), sharey=True)\n",
    "fig.suptitle('Average Price vs. Number of Rooms by Regionname')\n",
    "\n",
    "# Iterate over each Regionname and create a plot\n",
    "for i, region_name in enumerate(region_names):\n",
    "    # Filter data for the current Regionname\n",
    "    region_data = region_rooms_price_avg[region_name]\n",
    "    \n",
    "    # Extract number of rooms and average price\n",
    "    num_rooms = region_data.index\n",
    "    avg_price = region_data.values\n",
    "    \n",
    "    # Create a plot for the current Regionname\n",
    "    axs[i].plot(num_rooms, avg_price, '-o')\n",
    "    axs[i].set_title(region_name)\n",
    "    axs[i].set_xlabel('Number of Rooms')\n",
    "    axs[i].set_ylabel('Average Price')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
